{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation:\n",
    "Traditional RAG systems often use dense vector embeddings for retrieval, which can be computationally expensive and may not always capture the nuances of term importance. BM25 RAG addresses these limitations by using a probabilistic retrieval model that considers term frequency, inverse document frequency, and document length. This approach can lead to more accurate and interpretable retrieval, especially for queries requiring specific or rare information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/RAG/01_BM25_RAG/notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting qdrant_client\n",
      "  Downloading qdrant_client-1.12.1-py3-none-any.whl (267 kB)\n",
      "\u001b[K     |████████████████████████████████| 267 kB 511 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio-tools>=1.41.0\n",
      "  Downloading grpcio_tools-1.68.1-cp39-cp39-macosx_10_9_universal2.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker<3.0.0,>=2.7.0\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from qdrant_client) (2.0.2)\n",
      "Collecting grpcio>=1.41.0\n",
      "  Downloading grpcio-1.68.1-cp39-cp39-macosx_10_9_universal2.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.14 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from qdrant_client) (2.3.0)\n",
      "Collecting httpx[http2]>=0.20.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic>=1.10.8\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from grpcio-tools>=1.41.0->qdrant_client) (58.0.4)\n",
      "Collecting protobuf<6.0dev,>=5.26.1\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "\u001b[K     |████████████████████████████████| 417 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 691 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (2024.12.14)\n",
      "Requirement already satisfied: idna in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h2<5,>=3\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hpack<5,>=4.0\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting hyperframe<7,>=6.0\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.10.8->qdrant_client) (4.12.2)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 802 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx[http2]>=0.20.0->qdrant_client) (1.2.2)\n",
      "Installing collected packages: sniffio, h11, hyperframe, httpcore, hpack, anyio, pydantic-core, protobuf, httpx, h2, grpcio, annotated-types, pydantic, portalocker, grpcio-tools, qdrant-client\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.7.0 grpcio-1.68.1 grpcio-tools-1.68.1 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.7 httpx-0.28.1 hyperframe-6.0.1 portalocker-2.10.1 protobuf-5.29.2 pydantic-2.10.4 pydantic-core-2.27.2 qdrant-client-1.12.1 sniffio-1.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sseadmin/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama_index\n",
      "  Downloading llama_index-0.12.8-py3-none-any.whl (6.8 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
      "Collecting nltk>3.8.1\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 627 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting llama-index-core<0.13.0,>=0.12.8\n",
      "  Downloading llama_index_core-0.12.8-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting llama-index-question-gen-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_readers_file-0.4.1-py3-none-any.whl (38 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_agent_openai-0.4.1-py3-none-any.whl (13 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0\n",
      "  Downloading llama_index_llms_openai-0.3.12-py3-none-any.whl (14 kB)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting openai>=1.14.0\n",
      "  Downloading openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (3.2.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (1.6.0)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.17.0-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6\n",
      "  Downloading aiohttp-3.11.11-cp39-cp39-macosx_11_0_arm64.whl (455 kB)\n",
      "\u001b[K     |████████████████████████████████| 455 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (2.32.3)\n",
      "Collecting filetype<2.0.0,>=1.2.0\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading tiktoken-0.8.0-cp39-cp39-macosx_11_0_arm64.whl (983 kB)\n",
      "\u001b[K     |████████████████████████████████| 983 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (6.0.2)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: httpx in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (0.28.1)\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
      "  Downloading SQLAlchemy-2.0.36-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (4.12.2)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (2.10.4)\n",
      "Requirement already satisfied: numpy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (2.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (11.0.0)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting typing-inspect>=0.8.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama_index) (4.67.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.1-cp39-cp39-macosx_11_0_arm64.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting llama-cloud>=0.1.5\n",
      "  Downloading llama_cloud-0.1.7-py3-none-any.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi<2025.0.0,>=2024.7.4 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-cloud>=0.1.5->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama_index) (4.7.0)\n",
      "Requirement already satisfied: idna in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama_index) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama_index) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.8->llama_index) (0.14.0)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pypdf<6.0.0,>=5.1.0\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Collecting llama-parse>=0.5.0\n",
      "  Downloading llama_parse-0.5.18-py3-none-any.whl (15 kB)\n",
      "Collecting click<9.0.0,>=8.1.7\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: sniffio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.8.2-cp39-cp39-macosx_11_0_arm64.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.8->llama_index) (1.2.2)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.8->llama_index) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.8->llama_index) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama_index) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama_index) (3.4.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.1.1-cp39-cp39-macosx_11_0_universal2.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama_index) (24.2)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[K     |████████████████████████████████| 508 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.15.0)\n",
      "Installing collected packages: propcache, mypy-extensions, multidict, frozenlist, yarl, wrapt, typing-inspect, SQLAlchemy, marshmallow, greenlet, click, attrs, async-timeout, aiosignal, aiohappyeyeballs, tiktoken, tenacity, nltk, jiter, filetype, eval-type-backport, distro, dirtyjson, deprecated, dataclasses-json, aiohttp, openai, llama-index-core, llama-index-llms-openai, tzdata, soupsieve, pytz, llama-index-agent-openai, striprtf, pypdf, pandas, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, llama-cloud, beautifulsoup4, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-cli, llama-index\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 attrs-24.3.0 beautifulsoup4-4.12.3 click-8.1.8 dataclasses-json-0.6.7 deprecated-1.2.15 dirtyjson-1.0.8 distro-1.9.0 eval-type-backport-0.2.2 filetype-1.2.0 frozenlist-1.5.0 greenlet-3.1.1 jiter-0.8.2 llama-cloud-0.1.7 llama-index-0.12.8 llama-index-agent-openai-0.4.1 llama-index-cli-0.4.0 llama-index-core-0.12.8 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-llms-openai-0.3.12 llama-index-multi-modal-llms-openai-0.4.1 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.1 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.18 marshmallow-3.23.2 multidict-6.1.0 mypy-extensions-1.0.0 nltk-3.9.1 openai-1.58.1 pandas-2.2.3 propcache-0.2.1 pypdf-5.1.0 pytz-2024.2 soupsieve-2.6 striprtf-0.0.26 tenacity-9.0.0 tiktoken-0.8.0 typing-inspect-0.9.0 tzdata-2024.2 wrapt-1.17.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-embeddings-fastembed\n",
      "  Downloading llama_index_embeddings_fastembed-0.3.0-py3-none-any.whl (2.7 kB)\n",
      "Collecting fastembed>=0.2.2\n",
      "  Downloading fastembed-0.4.2-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 656 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-embeddings-fastembed) (0.12.8)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.21.0)\n",
      "Collecting onnx<2.0.0,>=1.15.0\n",
      "  Downloading onnx-1.17.0-cp39-cp39-macosx_12_0_universal2.whl (16.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.6 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting loguru<0.8.0,>=0.7.2\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 225 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.66 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (4.67.1)\n",
      "Collecting pillow<11.0.0,>=10.3.0\n",
      "  Downloading pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.0.2)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0\n",
      "  Downloading py_rust_stemmers-0.1.3-cp39-cp39-macosx_11_0_arm64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.20 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.27.0)\n",
      "Collecting onnxruntime<1.20.0,>=1.17.0\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-macosx_11_0_universal2.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 942 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.31 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.32.3)\n",
      "Collecting mmh3<5.0.0,>=4.1.0\n",
      "  Downloading mmh3-4.1.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (2024.12.0)\n",
      "Requirement already satisfied: filelock in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (24.2)\n",
      "Requirement already satisfied: wrapt in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.17.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.10.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.11.11)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.2.15)\n",
      "Requirement already satisfied: httpx in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.28.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.2.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (9.0.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.9.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.0.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.6.0)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.2.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.6.7)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.8.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.0.36)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.9.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.2.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (24.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.18.3)\n",
      "Requirement already satisfied: joblib in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.4.2)\n",
      "Requirement already satisfied: click in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2024.11.6)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from onnx<2.0.0,>=1.15.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (5.29.2)\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 330 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sympy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.13.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (2024.12.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.0.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.23.2)\n",
      "Requirement already satisfied: anyio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.3.0)\n",
      "Installing collected packages: humanfriendly, flatbuffers, coloredlogs, py-rust-stemmers, pillow, onnxruntime, onnx, mmh3, loguru, fastembed, llama-index-embeddings-fastembed\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "Successfully installed coloredlogs-15.0.1 fastembed-0.4.2 flatbuffers-24.12.23 humanfriendly-10.0 llama-index-embeddings-fastembed-0.3.0 loguru-0.7.3 mmh3-4.1.0 onnx-1.17.0 onnxruntime-1.19.2 pillow-10.4.0 py-rust-stemmers-0.1.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index\n",
    "%pip install llama-index-embeddings-fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-index-embeddings-fastembed in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (0.3.0)\n",
      "Requirement already satisfied: fastembed>=0.2.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-embeddings-fastembed) (0.4.2)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-embeddings-fastembed) (0.12.8)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (10.4.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (4.67.1)\n",
      "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.1.3)\n",
      "Requirement already satisfied: onnxruntime<1.20.0,>=1.17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.27.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.0.2)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (4.1.0)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.21.0)\n",
      "Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.17.0)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.7.3)\n",
      "Requirement already satisfied: filelock in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (6.0.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.6.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.8.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.0.36)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.2.15)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.9.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.11.11)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.2.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.0.8)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.6.7)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.17.0)\n",
      "Requirement already satisfied: httpx in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.28.1)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.2.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.10.4)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.4.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (24.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.18.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2024.11.6)\n",
      "Requirement already satisfied: click in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.4.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from onnx<2.0.0,>=1.15.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (5.29.2)\n",
      "Requirement already satisfied: sympy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.13.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (24.12.23)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (2.27.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from coloredlogs->onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (3.23.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.0.7)\n",
      "Requirement already satisfied: anyio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (4.7.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-fastembed) (1.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime<1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-vector-stores-qdrant\n",
      "  Downloading llama_index_vector_stores_qdrant-0.4.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.6 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-vector-stores-qdrant) (0.12.8)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-vector-stores-qdrant) (1.68.1)\n",
      "Requirement already satisfied: qdrant-client>=1.7.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-vector-stores-qdrant) (1.12.1)\n",
      "Requirement already satisfied: httpx in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.28.1)\n",
      "Requirement already satisfied: wrapt in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.17.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.6.7)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.6.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2024.12.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.2.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (9.0.0)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.2.2)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2.10.4)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2.32.3)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.2.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.2.15)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2.0.36)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.11.11)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (24.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.2.1)\n",
      "Requirement already satisfied: click in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2.27.2)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (2.10.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (1.68.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (2.3.0)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (5.29.2)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (58.0.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.0.7)\n",
      "Requirement already satisfied: anyio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (4.7.0)\n",
      "Requirement already satisfied: certifi in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (2024.12.14)\n",
      "Requirement already satisfied: idna in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.10)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (4.1.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (0.14.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from h2<5,>=3->httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from h2<5,>=3->httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (3.23.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.6->llama-index-vector-stores-qdrant) (24.2)\n",
      "Installing collected packages: llama-index-vector-stores-qdrant\n",
      "Successfully installed llama-index-vector-stores-qdrant-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sseadmin/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama_index.llms.ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama_index.embeddings.ollama\n",
      "  Downloading llama_index_embeddings_ollama-0.5.0-py3-none-any.whl (2.6 kB)\n",
      "Requirement already satisfied: ollama>=0.3.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama_index.embeddings.ollama) (0.4.4)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama_index.embeddings.ollama) (0.12.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.6.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2024.12.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.9.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.6.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.11.11)\n",
      "Requirement already satisfied: numpy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (4.12.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (9.0.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.2.15)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (4.67.1)\n",
      "Requirement already satisfied: httpx in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.27.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.32.3)\n",
      "Requirement already satisfied: wrapt in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.17.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.10.4)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.0.8)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.0.36)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (10.4.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.8.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.4.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.18.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (24.3.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2024.11.6)\n",
      "Requirement already satisfied: joblib in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.4.2)\n",
      "Requirement already satisfied: click in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (8.1.8)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (4.7.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (3.23.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.ollama) (24.2)\n",
      "Installing collected packages: llama-index.embeddings.ollama\n",
      "Successfully installed llama-index.embeddings.ollama-0.5.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index.embeddings.ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(\n",
    "    model=\"llama3.2\", \n",
    "    temperature=0.1,\n",
    "    context_window=8096,  # equivalent to max_tokens\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    embed_batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 1/1 [00:00<00:00,  2.34file/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data\", recursive=True).load_data(show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 15/15 [00:00<00:00, 5102.15it/s]\n",
      "Generating embeddings: 100%|██████████| 15/15 [01:36<00:00,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        MarkdownNodeParser(include_metadata=True),\n",
    "        # TokenTextSplitter(chunk_size=500, chunk_overlap=20),\n",
    "        # SentenceSplitter(chunk_size=1024, chunk_overlap=20),\n",
    "        # SemanticSplitterNodeParser(buffer_size=1, breakpoint_percentile_threshold=95 , embed_model=Settings.embed_model),\n",
    "        Settings.embed_model,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Ingest directly into a vector db\n",
    "nodes = pipeline.run(documents=documents , show_progress=True)\n",
    "print(\"Number of Nodes:\",len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "docstore.persist(persist_path=\"./docstore.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-retrievers-bm25\n",
      "  Downloading llama_index_retrievers_bm25-0.5.0-py3-none-any.whl (3.6 kB)\n",
      "Collecting bm25s<0.3.0,>=0.2.0\n",
      "  Downloading bm25s-0.2.6-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 663 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-retrievers-bm25) (0.12.8)\n",
      "Collecting pystemmer<3.0.0.0,>=2.2.0.1\n",
      "  Downloading PyStemmer-2.2.0.3-cp39-cp39-macosx_11_0_arm64.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 831 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.13.1)\n",
      "Requirement already satisfied: numpy in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.0.36)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.0.2)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.2.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.32.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.8.0)\n",
      "Requirement already satisfied: wrapt in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.17.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (9.0.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.6.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.67.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.2.1)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.8)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.11.11)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.9.1)\n",
      "Requirement already satisfied: httpx in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.12.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.12.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.10.4)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.18.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.4.4)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.1.0)\n",
      "Requirement already satisfied: click in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.11.6)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.23.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.2)\n",
      "Requirement already satisfied: anyio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.7.0)\n",
      "Requirement already satisfied: sniffio in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.2)\n",
      "Installing collected packages: pystemmer, bm25s, llama-index-retrievers-bm25\n",
      "Successfully installed bm25s-0.2.6 llama-index-retrievers-bm25-0.5.0 pystemmer-2.2.0.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "import Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass in the index, docstore, or list of nodes to create the retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=2,\n",
    "    # Optional: We can pass in the stemmer and set the language for stopwords\n",
    "    # This is important for removing stopwords and stemming the query + text\n",
    "    # The default is english for both\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 878 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.2)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.4.0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.3-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 675 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /Users/sseadmin/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.55.3 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.4 pyparsing-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:  60%|██████    | 9/15 [12:34<08:22, 83.79s/it]\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** cdef3399-50b8-4a0f-a25f-24d4d04eafdf<br>**Similarity:** 5.760929107666016<br>**Text:** Development of Multiple Combined Regression\n",
       "Methods for Rainfall Measurement.\n",
       "Nusrat Jahan Prottasha1, Md. Jashim Uddin 2, Md. Kowsher3, Rokeya Khatun\n",
       "Shorna4, Niaz Al Murshed 5, and Boktiar Ahmed Bappy 6\n",
       "1 Daﬀodil International University Dhaka 1207, Bangladesh,\n",
       "jahannusratprotta@gmail.com\n",
       "2 Noakhali Science and Technology University, 3814, Dhaka,\n",
       "mdjaud12@gmail.com\n",
       "3 Stevens Institute of Technology, Hoboken, NJ 07030 USA,\n",
       "ga.kowsher@gmail.com\n",
       "4 Daﬀodil International University, 1207, Dhaka,\n",
       "rokeyashorna5@gmail.com\n",
       "5 Jahangirnagar University, 1342, Dhaka,\n",
       "niazalmurshed.ai@gmail.com\n",
       "6 Jhenaidah polytechnic institute, 7300, Dhaka,\n",
       "entbappy73@gmail.com\n",
       "Abstract. Rainfall forecast is imperative as overwhelming precipitation\n",
       "can lead to numerous catastrophes. The prediction makes a diﬀerence for\n",
       "individuals to require preventive measures. In addition, the expectation\n",
       "ought to be precise. Most of the nations in the world is an agricultural\n",
       "nation and most of the economy of any nation depends upon agriculture.\n",
       "Rain plays an imperative part in agribusiness so the early expectation of\n",
       "rainfall plays a vital part within the economy of any agricultural. Over-\n",
       "whelming precipitation may well be a major disadvantage. It’s a cause\n",
       "for natural disasters like ﬂoods and drought that unit of measurement\n",
       "experienced by people over the world each year. Rainfall forecast has\n",
       "been one of the foremost challenging issues around the world in the ﬁnal\n",
       "year. There are so many techniques that have been invented for predict-\n",
       "ing rainfall but most of them are classiﬁcation, clustering techniques.\n",
       "Predicting the quantity of rain prediction is crucial for countries’ people.\n",
       "In our paperwork, we have proposed some regression analysis techniques\n",
       "which can be utilized for predicting the quantity of rainfall (The amount\n",
       "of rainfall recorded for the day in mm) based on some historical weather\n",
       "conditions dataset. we have applied 10 supervised regressors (Machine\n",
       "Learning Model) and some preprocessing methodology to the dataset.\n",
       "We have also analyzed the result and compared them using various sta-\n",
       "tistical parameters among these trained models to ﬁnd the bestperformed\n",
       "model. Using this model for predicting the quantity of rainfall in some\n",
       "diﬀerent places. Finally, the Random Forest regressor has predicted the\n",
       "best r2 score of 0.869904217, and the mean absolute error is 0.194459262,\n",
       "mean squared error is 0.126358647 and the root mean squared error is\n",
       "0.355469615. . .<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9fd739ac-06c2-4fc3-a8d8-44ae31442bad<br>**Similarity:** 3.0598549842834473<br>**Text:** 2 Nusrat Jahan et al.\n",
       "Keywords: Rainfall, Supervised Learning, Regression, Random Forest\n",
       "Tree, AdaBoost Regressor, Gradient Boosting Regressor, XGBoost.\n",
       "1 Introduction\n",
       "This research paper proposed a scientiﬁc method to predict rainfall quantity\n",
       "based on some diﬀerent weather conditions considering preceding weather records\n",
       "and present weather situations using some regression analysis techniques .[1]\n",
       "Rainfall determining is exceptionally vital since overwhelming and irregular rain-\n",
       "fall can have numerous impacts on many other things like annihilation of river-\n",
       "bank, crops, agriculture, and farms. One of the very deleterious departures is\n",
       "ﬂooding due to the over rain.[2] According to Wikipedia in late summer 2002,\n",
       "enormous storm downpours driven to gigantic ﬂooding in eastern India, Nepal,\n",
       "and Bangladesh, killing over 500 individuals and clearing out millions of houses.\n",
       "Each year in Bangladesh approximately 26,000 square kilometers (10,000 sq mi)\n",
       "(around 18% of the country) is ﬂooded, killing over 5,000 individuals and wreck-\n",
       "ing more than 7 million homes. On the other hand, Western Sydney is now\n",
       "the ”greatest concern” from the worst ﬂoods in decades to have ravaged east-\n",
       "ern Australia.[3] Jonh C, Rodda et al. presented a very rational method of the\n",
       "rainfall measurement problem. The application of science and innovation that\n",
       "predicts the state of the environment at any given speciﬁc period is known as\n",
       "climate determining or weather forecasting. There are many distinctive strate-\n",
       "gies for climate estimate and weather forecasting. But rainfall prediction is rare.\n",
       "Some of the research has shown some classiﬁcation method to predict whether\n",
       "it would be rain tomorrow or not. But instead of a classiﬁcation method for pre-\n",
       "dicting rain, we need to the quantity of the rainfall in a particular place. There\n",
       "is numerous equipment implement for foreseeing rainfall by utilizing the climate\n",
       "conditions like temperature, humidity, weight. These conventional strategies can-\n",
       "not work productively so by utilizing machine learning procedures. we can create\n",
       "an exact comes about rain forecast. Ready to fair do it by having the histori-\n",
       "cal information investigation of rainfall and can anticipate the precipitation for\n",
       "future seasons. In our paper, we presented some predictive regression analysis\n",
       "techniques to quantify rainfall quantity at a place. Here we used more than 10\n",
       "years of historical data to train our model. The dataset contains various weather\n",
       "conditions of diﬀerent places. This method can be utilized to predict the rainfall\n",
       "(The amount of rainfall recorded for the day in mm) and avoid the annihilation\n",
       "caused by it to life, agriculture, farm, and property. If we can quantify the rain-\n",
       "fall most people can make some decisions before overwhelmed rain-aﬀected. The\n",
       "contributions of this work are summarised as:\n",
       "– We have assessed a pipeline of making choices for evaluating the ﬁnest rea-\n",
       "sonable rain prediction.\n",
       "– We have utilized 10 supervised regressors (Machine Learning Model). Be-\n",
       "cause diﬀerent regressors give us diﬀerent results. So, it’s essential to ﬁnd\n",
       "out the right model according to the requirements.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# will retrieve context from specific companies\n",
    "retrieved_nodes = bm25_retriever.retrieve(\n",
    "    \"Why is Rainfall forecast imperative as overwhelming precipitation can lead to numerous catastrophes\"\n",
    ")\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=ResponseMode.COMPACT\n",
    ")\n",
    "\n",
    "BM25_QUERY_ENGINE = RetrieverQueryEngine(\n",
    "    retriever=bm25_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model requires more system memory (7.3 GiB) than is available (4.4 GiB)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mBM25_QUERY_ENGINE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhy is rainfall forecasting important to prevent disasters?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m response\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/query_engine/retriever_query_engine.py:179\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    176\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[1;32m    177\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m    178\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[0;32m--> 179\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/response_synthesizers/base.py:241\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    238\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[1;32m    239\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 241\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetadataMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    250\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py:43\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/response_synthesizers/refine.py:179\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[1;32m    184\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refine_response_single(\n\u001b[1;32m    185\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[1;32m    186\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/response_synthesizers/refine.py:241\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    240\u001b[0m             StructuredRefineResponse,\n\u001b[0;32m--> 241\u001b[0m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/response_synthesizers/refine.py:85\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     83\u001b[0m         answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mmodel_dump_json()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[38;5;241m=\u001b[39manswer, query_satisfied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/llms/llm.py:596\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[1;32m    595\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[0;32m--> 596\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/core/llms/callbacks.py:173\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    165\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    166\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     },\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    176\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    177\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    178\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    179\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_index/llms/ollama/base.py:306\u001b[0m, in \u001b[0;36mOllama.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m tools \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjson_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 306\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mollama_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response)\n\u001b[1;32m    318\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ollama/_client.py:332\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    289\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    290\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ollama/_client.py:177\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ollama/_client.py:122\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m   r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 122\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mResponseError\u001b[0m: model requires more system memory (7.3 GiB) than is available (4.4 GiB)"
     ]
    }
   ],
   "source": [
    "response = BM25_QUERY_ENGINE.query(\"Why is rainfall forecasting important to prevent disasters?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
