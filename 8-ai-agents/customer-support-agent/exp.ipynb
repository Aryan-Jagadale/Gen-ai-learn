{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    sentiment: str\n",
    "    response: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(state: State) -> State:\n",
    "    \"\"\"Categorize the customer query into Technical, Billing, or General.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following customer query into one of these categories: \"\n",
    "        \"Technical, Billing, General. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGroq(temperature=0, model=\"llama-3.3-70b-versatile\", max_tokens=4000,api_key='')\n",
    "    category = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"category\": category}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(state: State) -> State:\n",
    "    \"\"\"Analyze the sentiment of the customer query as Positive, Neutral, or Negative.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the sentiment of the following customer query. \"\n",
    "        \"Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGroq(temperature=0, model=\"llama-3.3-70b-versatile\", max_tokens=4000,api_key='')\n",
    "    sentiment = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"sentiment\": sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_technical(state: State) -> State:\n",
    "    \"\"\"Provide a technical support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a technical support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGroq(temperature=0, model=\"llama-3.3-70b-versatile\", max_tokens=4000,api_key='')\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_billing(state: State) -> State:\n",
    "    \"\"\"Provide a billing support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a billing support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGroq(temperature=0, model=\"llama-3.3-70b-versatile\", max_tokens=4000,api_key='')\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_general(state: State) -> State:\n",
    "    \"\"\"Provide a general support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a general support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatGroq(temperature=0, model=\"llama-3.3-70b-versatile\", max_tokens=4000,api_key='')\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalate(state: State) -> State:\n",
    "    \"\"\"Escalate the query to a human agent due to negative sentiment.\"\"\"\n",
    "    return {\"response\": \"This query has been escalated to a human agent due to its negative sentiment.\"}\n",
    "\n",
    "def route_query(state: State) -> str:\n",
    "    \"\"\"Route the query based on its sentiment and category.\"\"\"\n",
    "    if state[\"sentiment\"] == \"Negative\":\n",
    "        return \"escalate\"\n",
    "    elif state[\"category\"] == \"Technical\":\n",
    "        return \"handle_technical\"\n",
    "    elif state[\"category\"] == \"Billing\":\n",
    "        return \"handle_billing\"\n",
    "    else:\n",
    "        return \"handle_general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10d3bb890>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"categorize\", categorize)\n",
    "workflow.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "workflow.add_node(\"handle_technical\", handle_technical)\n",
    "workflow.add_node(\"handle_billing\", handle_billing)\n",
    "workflow.add_node(\"handle_general\", handle_general)\n",
    "workflow.add_node(\"escalate\", escalate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10d3bb890>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"categorize\", \"analyze_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10d3bb890>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"analyze_sentiment\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"handle_technical\": \"handle_technical\",\n",
    "        \"handle_billing\": \"handle_billing\",\n",
    "        \"handle_general\": \"handle_general\",\n",
    "        \"escalate\": \"escalate\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(\"handle_technical\", END)\n",
    "workflow.add_edge(\"handle_billing\", END)\n",
    "workflow.add_edge(\"handle_general\", END)\n",
    "workflow.add_edge(\"escalate\", END)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"categorize\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_customer_support(query: str) -> Dict[str, str]:\n",
    "    \"\"\"Process a customer query through the LangGraph workflow.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The customer's query\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the query's category, sentiment, and response\n",
    "    \"\"\"\n",
    "    results = app.invoke({\"query\": query})\n",
    "    return {\n",
    "        \"category\": results[\"category\"],\n",
    "        \"sentiment\": results[\"sentiment\"],\n",
    "        \"response\": results[\"response\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: My internet connection keeps dropping. Can you help?\n",
      "Category: The customer query \"My internet connection keeps dropping. Can you help?\" can be categorized as: Technical. \n",
      "\n",
      "This is because the query is related to a technical issue with the customer's internet connection, and they are seeking assistance to resolve the problem.\n",
      "Sentiment: Negative.\n",
      "Response: I'm so sorry to hear that your internet connection is dropping. That can be really frustrating. I'd be happy to help you troubleshoot the issue. \n",
      "\n",
      "To get started, can you please tell me a bit more about the problem you're experiencing? For example: \n",
      "\n",
      "1. How often does your internet connection drop?\n",
      "2. Are you using a wired or wireless connection?\n",
      "3. Have you made any recent changes to your network or devices?\n",
      "4. Are you getting any error messages when the connection drops?\n",
      "\n",
      "Additionally, you may want to try a few basic troubleshooting steps to see if they resolve the issue:\n",
      "\n",
      "1. Restart your router and modem to see if that stabilizes the connection.\n",
      "2. Check your cables and connections to ensure they are secure.\n",
      "3. Move closer to your router to rule out any range or interference issues.\n",
      "\n",
      "If none of these steps work, we can dive deeper into the issue and explore other possible causes. I'm here to help you get your internet connection up and running smoothly again.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"My internet connection keeps dropping. Can you help?\"\n",
    "result = run_customer_support(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Category: {result['category']}\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: where can i find my receipt?\n",
      "Category: The customer query \"where can I find my receipt?\" can be categorized as 'Billing'. This is because the query is related to a financial transaction and the customer is looking for a document that confirms their payment.\n",
      "Sentiment: Neutral. The customer is simply asking for information and does not express any emotion or opinion, so the sentiment is neutral.\n",
      "Response: If you're having trouble finding your receipt, don't worry, I'm here to help. There are a few possible places you can check, depending on how you made your purchase. \n",
      "\n",
      "1. **Email**: If you made an online purchase, check your email inbox for a confirmation email that may include your receipt. It's often sent to you immediately after the transaction is complete.\n",
      "2. **Order History**: If you have an account with the retailer, you can log in and check your order history. Many websites allow you to view and print receipts for past orders.\n",
      "3. **Store or Restaurant**: If you made a purchase in-store or at a restaurant, you can try contacting them directly to see if they have a copy of your receipt on file. They may be able to look it up for you or provide you with a replacement receipt.\n",
      "4. **Wallet or Purse**: If you made a purchase in-person, it's possible that you may have misplaced the physical receipt in your wallet or purse. Take a look through your belongings to see if it's tucked away somewhere.\n",
      "5. **Digital Wallets**: If you used a digital wallet like Apple Pay, Google Pay, or Samsung Pay, you can check your transaction history to see if the receipt is stored there.\n",
      "\n",
      "If you're still unable to find your receipt, feel free to provide more details about your purchase, such as the date and location, and I'll do my best to assist you further.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"where can i find my receipt?\"\n",
    "result = run_customer_support(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Category: {result['category']}\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
