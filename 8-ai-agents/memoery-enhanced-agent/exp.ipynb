{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0, model=\"llama-3.3-70b-versatile\", max_tokens=4000,api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store = {}\n",
    "long_term_memory = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in chat_store:\n",
    "        chat_store[session_id] = ChatMessageHistory()\n",
    "    return chat_store[session_id]\n",
    "\n",
    "def update_long_term_memory(session_id: str, input: str, output: str):\n",
    "    if session_id not in long_term_memory:\n",
    "        long_term_memory[session_id] = []\n",
    "    if len(input) > 20:  # Simple logic: store inputs longer than 20 characters\n",
    "        long_term_memory[session_id].append(f\"User said: {input}\")\n",
    "    if len(long_term_memory[session_id]) > 5:  # Keep only last 5 memories\n",
    "        long_term_memory[session_id] = long_term_memory[session_id][-5:]\n",
    "\n",
    "def get_long_term_memory(session_id: str):\n",
    "    return \". \".join(long_term_memory.get(session_id, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. Use the information from long-term memory if relevant.\"),\n",
    "    (\"system\", \"Long-term memory: {long_term_memory}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input_text: str, session_id: str):\n",
    "    long_term_mem = get_long_term_memory(session_id)\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"input\": input_text, \"long_term_memory\": long_term_mem},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    update_long_term_memory(session_id, input_text, response.content)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello Alice, it's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "AI: I'm not currently able to access real-time information or your location, Alice. However, I can suggest some ways for you to find out the weather. You can check a weather website or app on your device, or tune into a local news station for the latest forecast. Would you like some recommendations for weather websites or apps?\n",
      "AI: Sunny days can be so uplifting and energizing, can't they, Alice? There's something about the warmth and brightness of the sun that just makes everything feel more vibrant and alive. Do you have any fun plans or activities that you like to do on sunny days?\n",
      "AI: Your name is Alice. I remember you introduced yourself to me at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_123\"\n",
    "\n",
    "print(\"AI:\", chat(\"Hello! My name is Alice.\", session_id))\n",
    "print(\"AI:\", chat(\"What's the weather like today?\", session_id))\n",
    "print(\"AI:\", chat(\"I love sunny days.\", session_id))\n",
    "print(\"AI:\", chat(\"Do you remember my name?\", session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation History:\n",
      "human: Hello! My name is Alice.\n",
      "ai: Hello Alice, it's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "human: What's the weather like today?\n",
      "ai: I'm not currently able to access real-time information or your location, Alice. However, I can suggest some ways for you to find out the weather. You can check a weather website or app on your device, or tune into a local news station for the latest forecast. Would you like some recommendations for weather websites or apps?\n",
      "human: I love sunny days.\n",
      "ai: Sunny days can be so uplifting and energizing, can't they, Alice? There's something about the warmth and brightness of the sun that just makes everything feel more vibrant and alive. Do you have any fun plans or activities that you like to do on sunny days?\n",
      "human: Do you remember my name?\n",
      "ai: Your name is Alice. I remember you introduced yourself to me at the beginning of our conversation.\n",
      "\n",
      "Long-term Memory:\n",
      "User said: Hello! My name is Alice.. User said: What's the weather like today?. User said: Do you remember my name?\n"
     ]
    }
   ],
   "source": [
    "print(\"Conversation History:\")\n",
    "for message in chat_store[session_id].messages:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n",
    "print(\"\\nLong-term Memory:\")\n",
    "print(get_long_term_memory(session_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
