{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "import types\n",
    "import inspect\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection bug-reports already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m----> 2\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbug-reports\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGroq(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m,api_key\u001b[38;5;241m=\u001b[39mAPI_KEY)\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/api/client.py:147\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[0;34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    146\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[0;32m--> 147\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[1;32m    156\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[1;32m    157\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    158\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[1;32m    159\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/api/segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limit_enforcer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:23\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/api/segment.py:226\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[0;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    213\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    215\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Passing empty till backend changes are deployed.\u001b[39;49;00m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This is lazily populated on the first add\u001b[39;49;00m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[1;32m    239\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mprepare_segments_for_new_collection(coll)\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages/chromadb/db/mixins/sysdb.py:241\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[0;34m(self, id, name, configuration, segments, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[1;32m    236\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection\u001b[38;5;241m.\u001b[39mid, tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[1;32m    237\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    239\u001b[0m         )\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    243\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    245\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    252\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[0;31mUniqueConstraintError\u001b[0m: Collection bug-reports already exists"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name='bug-reports')\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0, max_tokens=4000,api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    function: Callable\n",
    "    function_string: str\n",
    "    arguments: list\n",
    "    error: bool\n",
    "    error_description: str = ''\n",
    "    new_function_string: str = ''\n",
    "    bug_report: str = ''\n",
    "    memory_search_results: list = []\n",
    "    memory_ids_to_update: list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_execution_node(state: State):\n",
    "    ''' Run Arbitrary Code '''\n",
    "    try:\n",
    "        print('\\nRunning Arbitrary Function')\n",
    "        print('--------------------------\\n')\n",
    "        result = state.function(*state.arguments)\n",
    "        print('\\n‚úÖ Arbitrary Function Ran Without Error')\n",
    "        print(f'Result: {result}')\n",
    "        print('---------------------------------------\\n')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Function Raised an Error: {e}')\n",
    "        state.error = True\n",
    "        state.error_description = str(e)\n",
    "    return state\n",
    "\n",
    "\n",
    "def code_update_node(state: State):\n",
    "    ''' Update Arbitratry Code '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with fixing a Python function that raised an error.'\n",
    "        'Function: {function_string}'\n",
    "        'Error: {error_description}' \n",
    "        'You must provide a fix for the present error only.'\n",
    "        'The bug fix should handle the thrown error case gracefully by returning an error message.'\n",
    "        'Do not raise an error in your bug fix.'\n",
    "        'The function must use the exact same name and parameters.'\n",
    "        'Your response must contain only the function definition with no additional text.'\n",
    "        'Your response must not contain any additional formatting, such as code delimiters or language declarations.'\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
    "    new_function_string = llm.invoke([message]).content.strip()\n",
    "\n",
    "    print('\\nüêõ Buggy Function')\n",
    "    print('-----------------\\n')\n",
    "    print(state.function_string)\n",
    "    print('\\nü©π Proposed Bug Fix')\n",
    "    print('-------------------\\n')\n",
    "    print(new_function_string)\n",
    "    \n",
    "    state.new_function_string = new_function_string\n",
    "    return state\n",
    "\n",
    "\n",
    "def code_patching_node(state: State):\n",
    "    ''' Fix Arbitrary Code '''\n",
    "    try:\n",
    "        print('\\n*******************')\n",
    "        print('\\n‚ù§Ô∏è‚Äçü©π Patching code...')\n",
    "        # Store the new function as a string\n",
    "        new_code = state.new_function_string\n",
    "        \n",
    "        # Create namespace for new function\n",
    "        namespace = {}\n",
    "        \n",
    "        # Execute new code in namespace\n",
    "        exec(new_code, namespace)\n",
    "        \n",
    "        # Get function name dynamically\n",
    "        func_name = state.function.__name__\n",
    "        \n",
    "        # Get the new function using dynamic name\n",
    "        new_function = namespace[func_name]\n",
    "        \n",
    "        # Update state\n",
    "        state.function = new_function\n",
    "        state.error = False\n",
    "\n",
    "        # Test the new function\n",
    "        result = state.function(*state.arguments)\n",
    "\n",
    "        print('...patch complete üò¨\\n')\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f'...patch failed: {e}')\n",
    "        print(f'Error details: {str(e)}')\n",
    "\n",
    "    print('******************\\n')\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_report_node(state: State):\n",
    "    ''' Generate Bug Report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with generating a bug report for a Python function that raised an error.'\n",
    "        'Function: {function_string}'\n",
    "        'Error: {error_description}'\n",
    "        'Your response must be a comprehensive string including only crucial information on the bug report'\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
    "    bug_report = llm.invoke([message]).content.strip()\n",
    "\n",
    "    print('\\nüìù Generating Bug Report')\n",
    "    print('------------------------\\n')\n",
    "    print(bug_report)\n",
    "\n",
    "    state.bug_report = bug_report\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_report_node(state: State):\n",
    "    ''' Generate Bug Report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with generating a bug report for a Python function that raised an error.'\n",
    "        'Function: {function_string}'\n",
    "        'Error: {error_description}'\n",
    "        'Your response must be a comprehensive string including only crucial information on the bug report'\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(function_string=state.function_string, error_description=state.error_description))\n",
    "    bug_report = llm.invoke([message]).content.strip()\n",
    "\n",
    "    print('\\nüìù Generating Bug Report')\n",
    "    print('------------------------\\n')\n",
    "    print(bug_report)\n",
    "\n",
    "    state.bug_report = bug_report\n",
    "    return state\n",
    "\n",
    "\n",
    "# Digest the bug report using the same template used when saving bug reports to increase the accuracy and relevance of results when querying the vector database.\n",
    "def memory_search_node(state: State):\n",
    "    ''' Find memories relevant to the current bug report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with archiving a bug report for a Python function that raised an error.'\n",
    "        'Bug Report: {bug_report}.'\n",
    "        'Your response must be a concise string including only crucial information on the bug report for future reference.'\n",
    "        'Format: # function_name ## error_description ### error_analysis'\n",
    "    )\n",
    "    \n",
    "    message = HumanMessage(content=prompt.format(\n",
    "        bug_report=state.bug_report,\n",
    "    ))\n",
    "    \n",
    "    response = llm.invoke([message]).content.strip()\n",
    "\n",
    "    results = collection.query(query_texts=[response])\n",
    "\n",
    "    print('\\nüîé Searching bug reports...')\n",
    "    if results['ids'][0]:\n",
    "        print(f'...{len(results[\"ids\"][0])} found.\\n')\n",
    "        print(results)\n",
    "        state.memory_search_results = [{'id':results['ids'][0][index], 'memory':results['documents'][0][index], 'distance':results['distances'][0][index]} for index, id in enumerate(results['ids'][0])]\n",
    "    else:\n",
    "        print('...none found.\\n')\n",
    "            \n",
    "    return state\n",
    "\n",
    "\n",
    "# Filter the top 30% of results to ensure the relevance of memories being updated.\n",
    "def memory_filter_node(state: State):\n",
    "    print('\\nüóëÔ∏è Filtering bug reports...')\n",
    "    for memory in state.memory_search_results:\n",
    "        if memory['distance'] < 0.3:\n",
    "            state.memory_ids_to_update.append(memory['id'])\n",
    "        \n",
    "    if state.memory_ids_to_update:\n",
    "        print(f'...{len(state.memory_ids_to_update)} selected.\\n')\n",
    "    else:\n",
    "        print('...none selected.\\n')\n",
    "            \n",
    "    return state\n",
    "\n",
    "\n",
    "# Condense the bug report before storing it in the vector database.\n",
    "def memory_generation_node(state: State):\n",
    "    ''' Generate relevant memories based on new bug report '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'You are tasked with archiving a bug report for a Python function that raised an error.'\n",
    "        'Bug Report: {bug_report}.'\n",
    "        'Your response must be a concise string including only crucial information on the bug report for future reference.'\n",
    "        'Format: # function_name ## error_description ### error_analysis'\n",
    "    )\n",
    "    \n",
    "    message = HumanMessage(content=prompt.format(\n",
    "        bug_report=state.bug_report,\n",
    "    ))\n",
    "    \n",
    "    response = llm.invoke([message]).content.strip()\n",
    "\n",
    "    print('\\nüíæ Saving Bug Report to Memory')\n",
    "    print('------------------------------\\n')\n",
    "    print(response)\n",
    "\n",
    "    id = str(uuid.uuid4())\n",
    "    collection.add(\n",
    "        ids=[id],\n",
    "        documents=[response],\n",
    "    )        \n",
    "    return state\n",
    "\n",
    "\n",
    "# Use the prior memory as well as the current bug report to generate an updated version of it.\n",
    "def memory_modification_node(state: State):\n",
    "    ''' Modify relevant memories based on new interaction '''\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        'Update the following memories based on the new interaction:'\n",
    "        'Current Bug Report: {bug_report}'\n",
    "        'Prior Bug Report: {memory_to_update}'\n",
    "        'Your response must be a concise but cumulative string including only crucial information on the current and prior bug reports for future reference.'\n",
    "        'Format: # function_name ## error_description ### error_analysis'\n",
    "    )\n",
    "    memory_to_update_id = state.memory_ids_to_update.pop(0)\n",
    "    state.memory_search_results.pop(0)\n",
    "    results = collection.get(ids=[memory_to_update_id])\n",
    "    memory_to_update = results['documents'][0]\n",
    "    message = HumanMessage(content=prompt.format(\n",
    "        bug_report=state.bug_report,\n",
    "        memory_to_update=memory_to_update,\n",
    "    ))\n",
    "    \n",
    "    response = llm.invoke([message]).content.strip()\n",
    "    \n",
    "    print('\\nCurrent Bug Report')\n",
    "    print('------------------\\n')\n",
    "    print(memory_to_update)\n",
    "    print('\\nWill be Replaced With')\n",
    "    print('---------------------\\n')\n",
    "    print(response)\n",
    "    \n",
    "    collection.update(\n",
    "        ids=[memory_to_update_id],\n",
    "        documents=[response],\n",
    "    )\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_router(state: State):\n",
    "    if state.error:\n",
    "        return 'bug_report_node'\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def memory_filter_router(state: State):\n",
    "    if state.memory_search_results:\n",
    "        return 'memory_filter_node'\n",
    "    else:\n",
    "        return 'memory_generation_node'\n",
    "\n",
    "\n",
    "def memory_generation_router(state: State):\n",
    "    if state.memory_ids_to_update:\n",
    "        return 'memory_modification_node'\n",
    "    else:\n",
    "        return 'memory_generation_node'\n",
    "\n",
    "\n",
    "def memory_update_router(state: State):\n",
    "    if state.memory_ids_to_update:\n",
    "        return 'memory_modification_node'\n",
    "    else:\n",
    "        return 'code_update_node'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11d87da90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes to the graph\n",
    "builder.add_node('code_execution_node', code_execution_node)\n",
    "builder.add_node('code_update_node', code_update_node)\n",
    "builder.add_node('code_patching_node', code_patching_node)\n",
    "builder.add_node('bug_report_node', bug_report_node)\n",
    "builder.add_node('memory_search_node', memory_search_node)\n",
    "builder.add_node('memory_filter_node', memory_filter_node)\n",
    "builder.add_node('memory_modification_node', memory_modification_node)\n",
    "builder.add_node('memory_generation_node', memory_generation_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edges to the graph\n",
    "builder.set_entry_point('code_execution_node')\n",
    "builder.add_conditional_edges('code_execution_node', error_router)\n",
    "builder.add_edge('bug_report_node', 'memory_search_node')\n",
    "builder.add_conditional_edges('memory_search_node', memory_filter_router)\n",
    "builder.add_conditional_edges('memory_filter_node', memory_generation_router)\n",
    "builder.add_edge('memory_generation_node', 'code_update_node')\n",
    "builder.add_conditional_edges('memory_modification_node', memory_update_router)\n",
    "\n",
    "builder.add_edge('code_update_node', 'code_patching_node')\n",
    "builder.add_edge('code_patching_node', 'code_execution_node')\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_self_healing_code_system(function, arguments):\n",
    "\n",
    "    state = State(\n",
    "        error=False,\n",
    "        function=function,\n",
    "        function_string=inspect.getsource(function),\n",
    "        arguments=arguments,\n",
    "    )\n",
    "    \n",
    "    return graph.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "*******************************\n",
      "** Testing Division Function **\n",
      "*******************************\n",
      "*******************************\n",
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "‚ùå Function Raised an Error: division by zero\n",
      "\n",
      "üìù Generating Bug Report\n",
      "------------------------\n",
      "\n",
      "\"Bug Report: Division by Zero Error in divide_two_numbers function. Error Message: division by zero. Function Parameters: a and b. Cause: The function does not handle the case when b is zero. Solution: Add a conditional statement to check if b is zero before performing division, raising a meaningful error or returning a specific value when b is zero.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sseadmin/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79.3M/79.3M [00:14<00:00, 5.63MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Searching bug reports...\n",
      "...none found.\n",
      "\n",
      "\n",
      "üíæ Saving Bug Report to Memory\n",
      "------------------------------\n",
      "\n",
      "# divide_two_numbers ## Division by Zero Error ### division by zero when b is zero, missing conditional check for b == 0\n",
      "\n",
      "üêõ Buggy Function\n",
      "-----------------\n",
      "\n",
      "def divide_two_numbers(a, b):\n",
      "    return a/b\n",
      "\n",
      "\n",
      "ü©π Proposed Bug Fix\n",
      "-------------------\n",
      "\n",
      "def divide_two_numbers(a, b):\n",
      "    try:\n",
      "        return a/b\n",
      "    except ZeroDivisionError:\n",
      "        return \"Error: Division by zero is not allowed\"\n",
      "\n",
      "*******************\n",
      "\n",
      "‚ù§Ô∏è‚Äçü©π Patching code...\n",
      "...patch complete üò¨\n",
      "\n",
      "******************\n",
      "\n",
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "\n",
      "‚úÖ Arbitrary Function Ran Without Error\n",
      "Result: Error: Division by zero is not allowed\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def divide_two_numbers(a, b):\n",
    "    return a/b\n",
    "\n",
    "# Test Cases\n",
    "print(\"*******************************\")\n",
    "print(\"*******************************\")\n",
    "print(\"** Testing Division Function **\")\n",
    "print(\"*******************************\")\n",
    "print(\"*******************************\")\n",
    "execute_self_healing_code_system(divide_two_numbers, [10, 0]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "‚ùå Function Raised an Error: unsupported operand type(s) for /: 'str' and 'int'\n",
      "\n",
      "üìù Generating Bug Report\n",
      "------------------------\n",
      "\n",
      "\"Bug Report: Division Function Error. Function Name: divide_two_numbers. Error Message: unsupported operand type(s) for /: 'str' and 'int'. Description: The function raised an error when attempting to divide a string by an integer, indicating that the function does not handle non-numeric input types. Reproduction Steps: Call the function with a string and an integer, e.g., divide_two_numbers('a', 2). Expected Result: The function should either perform the division or raise a meaningful error. Actual Result: The function raised a TypeError. Proposed Solution: Add input type checking to ensure both inputs are numbers before attempting division.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Searching bug reports...\n",
      "...1 found.\n",
      "\n",
      "{'ids': [['9f3210bf-a514-4bd2-b4f5-d8b8257e87cc']], 'embeddings': None, 'documents': [['# divide_two_numbers ## Division by Zero Error ### division by zero when b is zero, missing conditional check for b == 0']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.5651549696922302]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "\n",
      "üóëÔ∏è Filtering bug reports...\n",
      "...none selected.\n",
      "\n",
      "\n",
      "üíæ Saving Bug Report to Memory\n",
      "------------------------------\n",
      "\n",
      "# divide_two_numbers ## Division by non-numeric type ## TypeError due to unsupported operand types for division, requires input type checking to handle non-numeric inputs.\n",
      "\n",
      "üêõ Buggy Function\n",
      "-----------------\n",
      "\n",
      "def divide_two_numbers(a, b):\n",
      "    return a/b\n",
      "\n",
      "\n",
      "ü©π Proposed Bug Fix\n",
      "-------------------\n",
      "\n",
      "def divide_two_numbers(a, b):\n",
      "    try:\n",
      "        return a/b\n",
      "    except TypeError:\n",
      "        return \"Error: Both inputs must be numbers.\"\n",
      "\n",
      "*******************\n",
      "\n",
      "‚ù§Ô∏è‚Äçü©π Patching code...\n",
      "...patch complete üò¨\n",
      "\n",
      "******************\n",
      "\n",
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "\n",
      "‚úÖ Arbitrary Function Ran Without Error\n",
      "Result: Error: Both inputs must be numbers.\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_self_healing_code_system(divide_two_numbers, ['a', 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_string):\n",
    "    year, month, day = date_string.split('-')\n",
    "    return {'year': int(year), 'month': int(month), 'day': int(day)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Testing Date Parsing Function **\n",
      "***********************************\n",
      "***********************************\n",
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "‚ùå Function Raised an Error: not enough values to unpack (expected 3, got 1)\n",
      "\n",
      "üìù Generating Bug Report\n",
      "------------------------\n",
      "\n",
      "\"Bug Report: The function 'parse_date' raised an error due to insufficient date string values. The error 'not enough values to unpack (expected 3, got 1)' occurs when the input 'date_string' does not contain the expected '-' separator, resulting in only one value being returned by the 'split' method, instead of the required three values for year, month, and day. To fix this, input validation should be added to ensure the date string is in the correct format (YYYY-MM-DD) before attempting to parse it.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Searching bug reports...\n",
      "...2 found.\n",
      "\n",
      "{'ids': [['610d33a0-a169-4e07-83ac-0a7dab3e4a98', '9f3210bf-a514-4bd2-b4f5-d8b8257e87cc']], 'embeddings': None, 'documents': [['# divide_two_numbers ## Division by non-numeric type ## TypeError due to unsupported operand types for division, requires input type checking to handle non-numeric inputs.', '# divide_two_numbers ## Division by Zero Error ### division by zero when b is zero, missing conditional check for b == 0']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[1.2629616260528564, 1.5617167949676514]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "\n",
      "üóëÔ∏è Filtering bug reports...\n",
      "...none selected.\n",
      "\n",
      "\n",
      "üíæ Saving Bug Report to Memory\n",
      "------------------------------\n",
      "\n",
      "# parse_date ## not enough values to unpack (expected 3, got 1) ### insufficient date string values due to missing '-' separator, requiring input validation for correct YYYY-MM-DD format.\n",
      "\n",
      "üêõ Buggy Function\n",
      "-----------------\n",
      "\n",
      "def parse_date(date_string):\n",
      "    year, month, day = date_string.split('-')\n",
      "    return {'year': int(year), 'month': int(month), 'day': int(day)}\n",
      "\n",
      "\n",
      "ü©π Proposed Bug Fix\n",
      "-------------------\n",
      "\n",
      "def parse_date(date_string):\n",
      "    try:\n",
      "        year, month, day = date_string.split('-')\n",
      "        return {'year': int(year), 'month': int(month), 'day': int(day)}\n",
      "    except ValueError:\n",
      "        return 'Error: Invalid date format. Please use YYYY-MM-DD.'\n",
      "\n",
      "*******************\n",
      "\n",
      "‚ù§Ô∏è‚Äçü©π Patching code...\n",
      "...patch complete üò¨\n",
      "\n",
      "******************\n",
      "\n",
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "\n",
      "‚úÖ Arbitrary Function Ran Without Error\n",
      "Result: Error: Invalid date format. Please use YYYY-MM-DD.\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"** Testing Date Parsing Function **\")\n",
    "print(\"***********************************\")\n",
    "print(\"***********************************\")\n",
    "# Test 1: Invalid format\n",
    "execute_self_healing_code_system(parse_date, [\"2024/01/01\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "‚ùå Function Raised an Error: invalid literal for int() with base 10: 'abc'\n",
      "\n",
      "üìù Generating Bug Report\n",
      "------------------------\n",
      "\n",
      "Bug Report: The function 'parse_date' raised a ValueError due to an invalid literal 'abc' when attempting to convert it to an integer. The error occurred because the input 'date_string' contained non-numeric characters, which the function is not designed to handle. To fix this, input validation should be added to ensure 'date_string' is in the correct format 'YYYY-MM-DD' before attempting to parse it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Searching bug reports...\n",
      "...3 found.\n",
      "\n",
      "{'ids': [['efb0ac0d-a36a-4e59-8b2e-01fd8356f1ef', '610d33a0-a169-4e07-83ac-0a7dab3e4a98', '9f3210bf-a514-4bd2-b4f5-d8b8257e87cc']], 'embeddings': None, 'documents': [[\"# parse_date ## not enough values to unpack (expected 3, got 1) ### insufficient date string values due to missing '-' separator, requiring input validation for correct YYYY-MM-DD format.\", '# divide_two_numbers ## Division by non-numeric type ## TypeError due to unsupported operand types for division, requires input type checking to handle non-numeric inputs.', '# divide_two_numbers ## Division by Zero Error ### division by zero when b is zero, missing conditional check for b == 0']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.40036728978157043, 1.0570366382598877, 1.4807682037353516]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "\n",
      "üóëÔ∏è Filtering bug reports...\n",
      "...none selected.\n",
      "\n",
      "\n",
      "üíæ Saving Bug Report to Memory\n",
      "------------------------------\n",
      "\n",
      "# parse_date ## ValueError: invalid literal for int() with base 10: 'abc' ### Input validation needed for 'date_string' to ensure 'YYYY-MM-DD' format.\n",
      "\n",
      "üêõ Buggy Function\n",
      "-----------------\n",
      "\n",
      "def parse_date(date_string):\n",
      "    year, month, day = date_string.split('-')\n",
      "    return {'year': int(year), 'month': int(month), 'day': int(day)}\n",
      "\n",
      "\n",
      "ü©π Proposed Bug Fix\n",
      "-------------------\n",
      "\n",
      "def parse_date(date_string):\n",
      "    try:\n",
      "        year, month, day = date_string.split('-')\n",
      "        return {'year': int(year), 'month': int(month), 'day': int(day)}\n",
      "    except ValueError:\n",
      "        return 'Error: Invalid date format. Please use YYYY-MM-DD.'\n",
      "\n",
      "*******************\n",
      "\n",
      "‚ù§Ô∏è‚Äçü©π Patching code...\n",
      "...patch complete üò¨\n",
      "\n",
      "******************\n",
      "\n",
      "\n",
      "Running Arbitrary Function\n",
      "--------------------------\n",
      "\n",
      "\n",
      "‚úÖ Arbitrary Function Ran Without Error\n",
      "Result: Error: Invalid date format. Please use YYYY-MM-DD.\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_self_healing_code_system(parse_date, [\"abc-def-ghi\"]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
