{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import os\n",
    "from typing import Annotated, Dict, List, Optional, Tuple, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAVILY_API_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/2pgfb5b50c343r108b91w7f80000gn/T/ipykernel_98475/897254200.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model='nomic-embed-text', show_progress=True)\n"
     ]
    }
   ],
   "source": [
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0, max_tokens=4000,api_key='')\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Goals(BaseModel):\n",
    "    \"\"\"Structure for defining learning goals\"\"\"\n",
    "    goals: str = Field(None, description=\"Learning goals\")\n",
    "\n",
    "class LearningCheckpoint(BaseModel):\n",
    "    \"\"\"Structure for a single checkpoint\"\"\"\n",
    "    description: str = Field(..., description=\"Main checkpoint description\")\n",
    "    criteria: List[str] = Field(..., description=\"List of success criteria\")\n",
    "    verification: str = Field(..., description=\"How to verify this checkpoint\")\n",
    "\n",
    "class Checkpoints(BaseModel):\n",
    "    \"\"\"Main checkpoints container with index tracking\"\"\"\n",
    "    checkpoints: List[LearningCheckpoint] = Field(\n",
    "        ..., \n",
    "        description=\"List of checkpoints covering foundation, application, and mastery levels\"\n",
    "    )\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"Structure for search query collection\"\"\"\n",
    "    search_queries: list = Field(None, description=\"Search queries for retrieval.\")\n",
    "\n",
    "class LearningVerification(BaseModel):\n",
    "    \"\"\"Structure for verification results\"\"\"\n",
    "    understanding_level: float = Field(..., ge=0, le=1)\n",
    "    feedback: str\n",
    "    suggestions: List[str]\n",
    "    context_alignment: bool\n",
    "\n",
    "class FeynmanTeaching(BaseModel):\n",
    "    \"\"\"Structure for Feynman teaching method\"\"\"\n",
    "    simplified_explanation: str\n",
    "    key_concepts: List[str]\n",
    "    analogies: List[str]\n",
    "\n",
    "class QuestionOutput(BaseModel):\n",
    "    \"\"\"Structure for question generation output\"\"\"\n",
    "    question: str\n",
    "\n",
    "class InContext(BaseModel):\n",
    "    \"\"\"Structure for context verification\"\"\"\n",
    "    is_in_context: str = Field(..., description=\"Yes or No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningtState(TypedDict):\n",
    "    topic: str\n",
    "    goals: List[Goals]\n",
    "    context: str\n",
    "    context_chunks: Annotated[list, operator.add]\n",
    "    context_key: str\n",
    "    search_queries: SearchQuery\n",
    "    checkpoints: Checkpoints\n",
    "    verifications: LearningVerification\n",
    "    teachings: FeynmanTeaching\n",
    "    current_checkpoint: int\n",
    "    current_question: QuestionOutput\n",
    "    current_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_from_chunks(chunks):\n",
    "    \"\"\"Extract and combine content from chunks with splits attribute.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of chunk objects that may contain splits attribute\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all chunks joined with newlines\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'splits') and chunk.splits:\n",
    "            chunk_content = ' '.join(chunk.splits)\n",
    "            content.append(chunk_content)\n",
    "    \n",
    "    return '\\n'.join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_checkpoints_as_message(checkpoints: Checkpoints) -> str:\n",
    "    \"\"\"Convert Checkpoints object to a formatted string for the message.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints (Checkpoints): Checkpoints object containing learning checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing numbered checkpoints with descriptions and criteria\n",
    "    \"\"\"\n",
    "    message = \"Here are the learning checkpoints:\\n\\n\"\n",
    "    for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "        message += f\"Checkpoint {i}:\\n\"\n",
    "        message += f\"Description: {checkpoint.description}\\n\"\n",
    "        message += \"Success Criteria:\\n\"\n",
    "        for criterion in checkpoint.criteria:\n",
    "            message += f\"- {criterion}\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_checkpoint_message(checks: List[LearningCheckpoint]) -> HumanMessage:\n",
    "    \"\"\"Generate a formatted message for learning checkpoints that need context.\n",
    "    \n",
    "    Args:\n",
    "        checks (List[LearningCheckpoint]): List of learning checkpoint objects\n",
    "        \n",
    "    Returns:\n",
    "        HumanMessage: Formatted message containing checkpoint descriptions, criteria and \n",
    "                     verification methods, ready for context search\n",
    "    \"\"\"\n",
    "    formatted_checks = []\n",
    "    \n",
    "    for check in checks:\n",
    "        checkpoint_text = f\"\"\"\n",
    "        Description: {check.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f'- {criterion}' for criterion in check.criteria)}\n",
    "        Verification Method: {check.verification}\n",
    "        \"\"\"\n",
    "        formatted_checks.append(checkpoint_text)\n",
    "    \n",
    "    all_checks = \"\\n---\\n\".join(formatted_checks)\n",
    "    \n",
    "    checkpoints_message = HumanMessage(content=f\"\"\"The following learning checkpoints need additional context:\n",
    "        {all_checks}\n",
    "        \n",
    "        Please generate search queries to find relevant information.\"\"\")\n",
    "    \n",
    "    return checkpoints_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_checkpoints_generator = SystemMessage(content=\"\"\"You will be given a learning topic title and learning objectives.\n",
    "Your goal is to generate clear learning checkpoints that will help verify understanding and progress through the topic.\n",
    "The output should be in the following dictionary structure:\n",
    "checkpoint \n",
    "-> description (level checkpoint description)\n",
    "-> criteria\n",
    "-> verification (How to verify this checkpoint (Feynman Methods))\n",
    "Requirements for each checkpoint:\n",
    "- Description should be clear and concise\n",
    "- Criteria should be specific and measurable (3-5 items)\n",
    "- Verification method should be practical and appropriate for the level\n",
    "- Verification will be checked by language model, so it must by in natural language\n",
    "- All elements should align with the learning objectives\n",
    "- Use action verbs and clear language\n",
    "Ensure all checkpoints progress logically from foundation to mastery.\n",
    "IMPORTANT - ANSWER ONLY 3 CHECKPOINTS\"\"\")\n",
    "\n",
    "checkpoint_based_query_generator = SystemMessage(content=\"\"\"You will be given learning checkpoints for a topic.\n",
    "Your goal is to generate search queries that will retrieve content matching each checkpoint's requirements from retrieval systems or web search.\n",
    "Follow these steps:\n",
    "1. Analyze each learning checkpoint carefully\n",
    "2. For each checkpoint, generate ONE targeted search query that will retrieve:\n",
    "   - Content for checkpoint verification\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_context = SystemMessage(content=\"\"\"You will be given a learning criteria and context.\n",
    "Check if the the criteria could be answered using the context.\n",
    "Always answer YES or NO\"\"\")\n",
    "\n",
    "question_generator = SystemMessage(content=\"\"\"You will be given a checkpoint description, success criteria, and verification method.\n",
    "Your goal is to generate an appropriate question that aligns with the checkpoint's verification requirements.\n",
    "The question should:\n",
    "1. Follow the specified verification method\n",
    "2. Cover all success criteria\n",
    "3. Encourage demonstration of understanding\n",
    "4. Be clear and specific\n",
    "Output should be a single, well-formulated question that effectively tests the checkpoint's learning objectives.\"\"\")\n",
    "\n",
    "answer_verifier = SystemMessage(content=\"\"\"You will be given a student's answer, question, checkpoint details, and relevant context.\n",
    "Your goal is to analyze the answer against the checkpoint criteria and provided context.\n",
    "Analyze considering:\n",
    "1. Alignment with verification method specified\n",
    "2. Coverage of all success criteria\n",
    "3. Use of relevant concepts from context\n",
    "4. Depth and accuracy of understanding\n",
    "Output should include:\n",
    "- understanding_level: float between 0 and 1\n",
    "- feedback: detailed explanation of the assessment\n",
    "- suggestions: list of specific improvements\n",
    "- context_alignment: boolean indicating if the answer aligns with provided context\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feynman_teacher = SystemMessage(content=\"\"\"You will be given verification results, checkpoint criteria, and learning context.\n",
    "Your goal is to create a Feynman-style teaching explanation for concepts that need reinforcement.\n",
    "The explanation should include:\n",
    "1. Simplified explanation without technical jargon\n",
    "2. Concrete, relatable analogies\n",
    "3. Key concepts to remember\n",
    "Output should follow the Feynman technique:\n",
    "- simplified_explanation: clear, jargon-free explanation\n",
    "- key_concepts: list of essential points\n",
    "- analogies: list of relevant, concrete comparisons\n",
    "Focus on making complex ideas accessible and memorable.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextStore:\n",
    "    \"\"\"Store for managing context chunks and their embeddings in memory.\n",
    "    \n",
    "    A class that provides storage and retrieval of context data using an in-memory store.\n",
    "    Each context entry consists of context chunks and their corresponding embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize ContextStore with an empty in-memory store.\"\"\"\n",
    "        self.store = InMemoryStore()\n",
    "        \n",
    "    def save_context(self, context_chunks: list, embeddings: list, key: str = None):\n",
    "        \"\"\"Save context chunks and their embeddings to the store.\n",
    "        \n",
    "        Args:\n",
    "            context_chunks (list): List of context chunk objects\n",
    "            embeddings (list): List of corresponding embeddings for the chunks\n",
    "            key (str, optional): Custom key for storing the context. Defaults to None,\n",
    "                               in which case a UUID is generated.\n",
    "            \n",
    "        Returns:\n",
    "            str: The key used to store the context\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        \n",
    "        if key is None:\n",
    "            key = str(uuid.uuid4())\n",
    "            \n",
    "        value = {\n",
    "            \"chunks\": context_chunks,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "        \n",
    "        self.store.put(namespace, key, value)\n",
    "        return key\n",
    "        \n",
    "    def get_context(self, context_key: str):\n",
    "        \"\"\"Retrieve context data from the store using a key.\n",
    "        \n",
    "        Args:\n",
    "            context_key (str): The key used to store the context\n",
    "            \n",
    "        Returns:\n",
    "            dict: The stored context value containing chunks and embeddings\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        memory = self.store.get(namespace, context_key)\n",
    "        return memory.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(state: LearningtState):\n",
    "    \"\"\"Generates search queries based on learning checkpoints from current state.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(SearchQuery) \n",
    "    checkpoints_message = HumanMessage(content=format_checkpoints_as_message(state['checkpoints']))  \n",
    "    messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "    search_queries = structured_llm.invoke(messages)\n",
    "    return {\"search_queries\": search_queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state: LearningtState):\n",
    "    \"\"\"Retrieves and processes web search results based on search queries.\"\"\"\n",
    "    search_queries = state[\"search_queries\"].search_queries\n",
    "    \n",
    "    all_search_docs = []\n",
    "    for query in search_queries:\n",
    "        search_docs = tavily_search.invoke(query)\n",
    "        all_search_docs.extend(search_docs)\n",
    "    \n",
    "    formatted_search_docs = [\n",
    "        f'Context: {doc[\"content\"]}\\n Source: {doc[\"url\"]}\\n'\n",
    "        for doc in all_search_docs\n",
    "    ]\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(formatted_search_docs)\n",
    "    context_key = context_store.save_context(\n",
    "        formatted_search_docs,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    \n",
    "    return {\"context_chunks\": formatted_search_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_checkpoints(state: LearningtState):\n",
    "    \"\"\"Creates learning checkpoints based on given topic and goals.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(Checkpoints)\n",
    "    messages = [\n",
    "        learning_checkpoints_generator,\n",
    "        SystemMessage(content=f\"Topic: {state['topic']}\"),\n",
    "        SystemMessage(content=f\"Goals: {', '.join(str(goal) for goal in state['goals'])}\")\n",
    "    ]\n",
    "    checkpoints = structured_llm.invoke(messages)\n",
    "    return {\"checkpoints\": checkpoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_context(state: LearningtState):\n",
    "    \"\"\"Splits context into manageable chunks and generates their embeddings.\"\"\"\n",
    "    encoder = OllamaEmbeddings(model='nomic-embed-text', show_progress=True)\n",
    "    \n",
    "    # Replace StatisticalChunker with RecursiveCharacterTextSplitter\n",
    "    chunker = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,  # Max tokens per chunk (adjust as needed)\n",
    "        chunk_overlap=20,  # Overlap between chunks\n",
    "        length_function=len  # Default uses character length; adjust if token count needed\n",
    "    )\n",
    "    \n",
    "    # Split the context into chunks\n",
    "    chunks = chunker.split_text(state['context'])\n",
    "    content = chunks  # No need for extract_content_from_chunks since it's plain text now\n",
    "\n",
    "    # Generate embeddings\n",
    "    chunk_embeddings = encoder.embed_documents(content)\n",
    "    context_key = context_store.save_context(\n",
    "        content,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    return {\"context_chunks\": content, \"context_key\": context_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_validation(state: LearningtState):\n",
    "    \"\"\"Validates context coverage against checkpoint criteria using stored embeddings.\"\"\"\n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    checks = []\n",
    "    structured_llm = llm.with_structured_output(InContext)\n",
    "    \n",
    "    for checkpoint in state['checkpoints'].checkpoints:\n",
    "        query = embeddings.embed_query(checkpoint.verification)\n",
    "        \n",
    "        similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "        top_3_indices = sorted(range(len(similarities)), \n",
    "                             key=lambda i: similarities[i], \n",
    "                             reverse=True)[:3]\n",
    "        relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "        \n",
    "        messages = [\n",
    "            validate_context,\n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Criteria:\n",
    "            {chr(10).join(f\"- {c}\" for c in checkpoint.criteria)}\n",
    "            \n",
    "            Context:\n",
    "            {chr(10).join(relevant_chunks)}\n",
    "            \"\"\")\n",
    "        ]\n",
    "        \n",
    "        response = structured_llm.invoke(messages)\n",
    "        if response.is_in_context.lower() == \"no\":\n",
    "            checks.append(checkpoint)\n",
    "    \n",
    "    if checks:\n",
    "        structured_llm = llm.with_structured_output(SearchQuery)\n",
    "        checkpoints_message = generate_checkpoint_message(checks)\n",
    "        \n",
    "        messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "        search_queries = structured_llm.invoke(messages)\n",
    "        return {\"search_queries\": search_queries}\n",
    "    \n",
    "    return {\"search_queries\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(state: LearningtState):\n",
    "    \"\"\"Generates assessment questions based on current checkpoint verification requirements.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(QuestionOutput)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        question_generator,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Generate an appropriate verification question.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    question_output = structured_llm.invoke(messages)\n",
    "    return {\"current_question\": question_output.question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_answer(state: LearningtState):\n",
    "    \"\"\"Evaluates user answers against checkpoint criteria using relevant context chunks.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(LearningVerification)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    query = embeddings.embed_query(checkpoint_info.verification)\n",
    "    \n",
    "    similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "    top_3_indices = sorted(range(len(similarities)), \n",
    "                         key=lambda i: similarities[i], \n",
    "                         reverse=True)[:3]\n",
    "    relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "    \n",
    "    messages = [\n",
    "        answer_verifier,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Question: {state['current_question']}\n",
    "        Answer: {state['current_answer']}\n",
    "        \n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Context:\n",
    "        {chr(10).join(relevant_chunks)}\n",
    "        \n",
    "        Assess the answer.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    verification = structured_llm.invoke(messages)\n",
    "    return {\"verifications\": verification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach_concept(state: LearningtState):\n",
    "    \"\"\"Creates simplified Feynman-style explanations for concepts that need reinforcement.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(FeynmanTeaching)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        feynman_teacher,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Criteria: {checkpoint_info.criteria}\n",
    "        Verification: {state['verifications']}\n",
    "        \n",
    "        Context:\n",
    "        {state['context_chunks']}\n",
    "        \n",
    "        Create a Feynman teaching explanation.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    teaching = structured_llm.invoke(messages)\n",
    "    return {\"teachings\": teaching}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_answer(state: LearningtState):\n",
    "    \"\"\"Placeholder for handling user's answer input.\"\"\"\n",
    "    pass\n",
    "\n",
    "def next_checkpoint(state: LearningtState):\n",
    "    \"\"\"Advances to the next checkpoint in the learning sequence.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint'] + 1\n",
    "    return {'current_checkpoint': current_checkpoint}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_context(state: LearningtState):\n",
    "    \"\"\"Determines whether to process existing context or generate new search queries.\"\"\"\n",
    "    if state.get(\"context\"):\n",
    "        return 'chunk_context'\n",
    "    return 'generate_query'\n",
    "\n",
    "def route_verification(state: LearningtState):\n",
    "    \"\"\"Determines next step based on verification results and checkpoint progress.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    \n",
    "    if state['verifications'].understanding_level < 0.7:\n",
    "        return 'teach_concept'\n",
    "        \n",
    "    if current_checkpoint + 1 < len(state['checkpoints'].checkpoints):\n",
    "        return 'next_checkpoint'\n",
    "    \n",
    "    return END\n",
    "\n",
    "def route_teaching(state: LearningtState):\n",
    "    \"\"\"Routes to next checkpoint or ends session after teaching intervention.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    if current_checkpoint + 1 < len(state['checkpoints'].checkpoints):\n",
    "        return 'next_checkpoint'\n",
    "    return END\n",
    "\n",
    "def route_search(state: LearningtState):\n",
    "    \"\"\"Directs flow between question generation and web search based on query status.\"\"\"\n",
    "    if state['search_queries'] is None:\n",
    "        return \"generate_question\"\n",
    "    return \"search_web\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122c11010>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher = StateGraph(LearningtState)\n",
    "memory = MemorySaver()\n",
    "context_store = ContextStore()\n",
    "\n",
    "searcher.add_node(\"generate_query\", generate_query)\n",
    "searcher.add_node(\"search_web\", search_web)\n",
    "searcher.add_node(\"chunk_context\", chunk_context)\n",
    "searcher.add_node(\"context_validation\", context_validation)\n",
    "searcher.add_node(\"generate_checkpoints\", generate_checkpoints)\n",
    "searcher.add_node(\"generate_question\", generate_question)\n",
    "searcher.add_node(\"next_checkpoint\", next_checkpoint)\n",
    "searcher.add_node(\"user_answer\", user_answer)\n",
    "searcher.add_node(\"verify_answer\", verify_answer)\n",
    "searcher.add_node(\"teach_concept\", teach_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x122c11010>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flow\n",
    "searcher.add_edge(START, \"generate_checkpoints\")\n",
    "searcher.add_conditional_edges('generate_checkpoints', route_context,['chunk_context', 'generate_query'])\n",
    "searcher.add_edge(\"generate_query\", \"search_web\")\n",
    "searcher.add_edge(\"search_web\", \"generate_question\")\n",
    "searcher.add_edge(\"chunk_context\", 'context_validation')\n",
    "searcher.add_conditional_edges('context_validation', route_search,['search_web', 'generate_question'])\n",
    "\n",
    "searcher.add_edge(\"generate_question\", \"user_answer\")\n",
    "searcher.add_edge(\"user_answer\", \"verify_answer\")\n",
    "searcher.add_conditional_edges(\n",
    "    \"verify_answer\",\n",
    "    route_verification,\n",
    "    {\n",
    "        \"next_checkpoint\": \"next_checkpoint\",\n",
    "        \"teach_concept\": \"teach_concept\",\n",
    "        END: END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.add_conditional_edges(\n",
    "    \"teach_concept\",\n",
    "    route_teaching,\n",
    "    {\n",
    "        \"next_checkpoint\": \"next_checkpoint\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "searcher.add_edge(\"next_checkpoint\", \"generate_question\")\n",
    "\n",
    "\n",
    "\n",
    "graph = searcher.compile(interrupt_after=[\"generate_checkpoints\"], interrupt_before=[\"user_answer\"], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_checkpoints(event):\n",
    "    \"\"\"Pretty print checkpoints information with improved visual formatting\"\"\"\n",
    "    checkpoints = event.get('checkpoints', '')\n",
    "    if checkpoints:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üéØ LEARNING CHECKPOINTS OVERVIEW\".center(80))\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "            # Checkpoint header with number\n",
    "            print(f\"üìç CHECKPOINT #{i}\".center(80))\n",
    "            print(\"‚îÄ\" * 80 + \"\\n\")\n",
    "            \n",
    "            # Description section with text wrapping\n",
    "            print(\"üìù Description:\")\n",
    "            print(\"‚îÄ\" * 40)\n",
    "            words = checkpoint.description.split()\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 70:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    print(f\"  {' '.join(current_line)}\")\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                print(f\"  {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Success Criteria section\n",
    "            print(\"‚úÖ Success Criteria:\")\n",
    "            print(\"‚îÄ\" * 40)\n",
    "            for j, criterion in enumerate(checkpoint.criteria, 1):\n",
    "                # Wrap each criterion text\n",
    "                words = criterion.split()\n",
    "                current_line = []\n",
    "                current_length = 0\n",
    "                first_line = True\n",
    "                \n",
    "                for word in words:\n",
    "                    if current_length + len(word) + 1 <= 66:  # Shorter width to account for numbering\n",
    "                        current_line.append(word)\n",
    "                        current_length += len(word) + 1\n",
    "                    else:\n",
    "                        if first_line:\n",
    "                            print(f\"  {j}. {' '.join(current_line)}\")\n",
    "                            first_line = False\n",
    "                        else:\n",
    "                            print(f\"     {' '.join(current_line)}\")\n",
    "                        current_line = [word]\n",
    "                        current_length = len(word)\n",
    "                \n",
    "                if current_line:\n",
    "                    if first_line:\n",
    "                        print(f\"  {j}. {' '.join(current_line)}\")\n",
    "                    else:\n",
    "                        print(f\"     {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Verification Method section\n",
    "            print(\"üîç Verification Method:\")\n",
    "            print(\"‚îÄ\" * 40)\n",
    "            words = checkpoint.verification.split()\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 70:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    print(f\"  {' '.join(current_line)}\")\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                print(f\"  {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Separator between checkpoints\n",
    "            if i < len(checkpoints.checkpoints):\n",
    "                print(\"~\" * 80 + \"\\n\")\n",
    "        \n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "def print_verification_results(event):\n",
    "    \"\"\"Pretty print verification results with improved formatting\"\"\"\n",
    "    verifications = event.get('verifications', '')\n",
    "    if verifications:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"üìä VERIFICATION RESULTS\".center(50))\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "        # Understanding Level with visual bar\n",
    "        understanding = verifications.understanding_level\n",
    "        bar_length = 20\n",
    "        filled_length = int(understanding * bar_length)\n",
    "        bar = \"‚ñà\" * filled_length + \"‚ñë\" * (bar_length - filled_length)\n",
    "        \n",
    "        print(f\"üìà Understanding Level: [{bar}] {understanding * 100:.1f}%\\n\")\n",
    "        \n",
    "        # Feedback section\n",
    "        print(\"üí° Feedback:\")\n",
    "        print(f\"{verifications.feedback}\\n\")\n",
    "        \n",
    "        # Suggestions section\n",
    "        print(\"üéØ Suggestions:\")\n",
    "        for i, suggestion in enumerate(verifications.suggestions, 1):\n",
    "            print(f\"  {i}. {suggestion}\")\n",
    "        print()\n",
    "        \n",
    "        # Context Alignment\n",
    "        print(\"üîç Context Alignment:\")\n",
    "        print(f\"{verifications.context_alignment}\\n\")\n",
    "        \n",
    "        print(\"-\" * 50 + \"\\n\")\n",
    "def print_teaching_results(event):\n",
    "    \"\"\"Pretty print Feynman teaching results with improved formatting\"\"\"\n",
    "    teachings = event.get('teachings', '')\n",
    "    if teachings:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üéì FEYNMAN TEACHING EXPLANATION\".center(70))\n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        # Simplified Explanation section\n",
    "        print(\"üìö SIMPLIFIED EXPLANATION:\")\n",
    "        print(\"‚îÄ\" * 30)\n",
    "        # Split explanation into paragraphs for better readability\n",
    "        paragraphs = teachings.simplified_explanation.split('\\n')\n",
    "        for paragraph in paragraphs:\n",
    "            # Wrap text at 60 characters for better readability\n",
    "            words = paragraph.split()\n",
    "            lines = []\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 60:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    lines.append(' '.join(current_line))\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                lines.append(' '.join(current_line))\n",
    "            \n",
    "            for line in lines:\n",
    "                print(f\"{line}\")\n",
    "            print()\n",
    "        \n",
    "        # Key Concepts section\n",
    "        print(\"üí° KEY CONCEPTS:\")\n",
    "        print(\"‚îÄ\" * 30)\n",
    "        for i, concept in enumerate(teachings.key_concepts, 1):\n",
    "            print(f\"  {i}. {concept}\")\n",
    "        print()\n",
    "        \n",
    "        # Analogies section\n",
    "        print(\"üîÑ ANALOGIES & EXAMPLES:\")\n",
    "        print(\"‚îÄ\" * 30)\n",
    "        for i, analogy in enumerate(teachings.analogies, 1):\n",
    "            print(f\"  {i}. {analogy}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "note = \"\"\"Anemia: A Comprehensive Overview\n",
    "Definition\n",
    "Anemia is a medical condition characterized by a decrease in the total number of red blood cells (RBCs) or hemoglobin in the blood. This reduction leads to a diminished ability to carry oxygen to the body's tissues, affecting overall body function and health.\n",
    "Blood Components and Their Role\n",
    "Red blood cells, also known as erythrocytes, are fundamental components of blood that carry oxygen throughout the body. These cells contain hemoglobin, an iron-containing protein that gives blood its characteristic red color and is responsible for oxygen transport. The typical lifespan of a red blood cell is approximately 120 days, after which it must be replaced by new cells produced in the bone marrow.\n",
    "Types of Anemia\n",
    "Iron Deficiency Anemia represents the most prevalent form of anemia worldwide. It occurs due to insufficient iron intake or absorption, particularly affecting pregnant women, growing children, menstruating women, and individuals with poor nutritional intake.\n",
    "Vitamin Deficiency Anemia develops when the body lacks sufficient amounts of vitamin B12 or folate (vitamin B9). This deficiency can stem from dietary inadequacies or problems with nutrient absorption in the digestive system.\n",
    "Aplastic Anemia, though rare, presents a serious condition where the bone marrow fails to produce adequate blood cells. This form can be either inherited through genetic factors or acquired through various environmental causes or medical conditions.\n",
    "Hemolytic Anemia occurs when red blood cells are destroyed at a rate faster than the body can replace them. This condition may be inherited through genetic factors or acquired through various external causes.\n",
    "Clinical Manifestations\n",
    "Anemia manifests through various symptoms including persistent fatigue and weakness. Patients often present with pale or yellowish skin, experience shortness of breath, and may suffer from dizziness. Additional symptoms include irregular heartbeat patterns, frequent headaches, cold extremities, and occasional chest pain.\n",
    "Diagnostic Approach\n",
    "Diagnosis begins with a thorough physical examination by a healthcare provider. Blood tests form the cornerstone of diagnosis, including a Complete Blood Count (CBC), assessment of iron levels, vitamin B12 measurement, and folate level determination. These tests help identify the specific type of anemia and guide appropriate treatment.\n",
    "Treatment Strategies\n",
    "Dietary modification serves as a fundamental treatment approach. This involves increasing consumption of iron-rich foods such as red meat, dark leafy vegetables, legumes, and iron-fortified cereals.\n",
    "Supplementation often proves necessary and may include iron supplements, vitamin B12, or folic acid, depending on the underlying cause of anemia.\n",
    "Medical interventions become necessary in severe cases. Blood transfusions may be required for severe anemia, while bone marrow transplantation might be considered for cases of aplastic anemia.\n",
    "Preventive Measures\n",
    "Prevention centers on maintaining a balanced diet rich in essential nutrients, particularly iron, vitamin B12, folate, and vitamin C, which enhances iron absorption. Regular medical check-ups allow for early detection and intervention.\n",
    "Certain populations require special attention regarding prevention. These include pregnant women, menstruating women, growing children, individuals following vegetarian or vegan diets, and athletes who may have increased nutritional demands.\n",
    "Potential Complications\n",
    "Untreated anemia can lead to several serious complications. These include severe fatigue that impacts daily activities, complications during pregnancy, cardiovascular problems, depression, and cognitive difficulties that may affect work or school performance.\n",
    "Clinical Significance\n",
    "Anemia often serves as an indicator of other underlying medical conditions. Therefore, early detection and appropriate treatment prove crucial for optimal outcomes. Different forms of anemia require specific treatment approaches, and regular monitoring may be necessary to ensure treatment effectiveness.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = {\n",
    "    \"topic\": \"Anemia\",\n",
    "    'goals': ['Im medical student, i want to master the diagnosis of Anemia'],\n",
    "    'context': note,\n",
    "    'current_checkpoint': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        üéØ LEARNING CHECKPOINTS OVERVIEW                         \n",
      "================================================================================\n",
      "\n",
      "                                üìç CHECKPOINT #1                                 \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìù Description:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Foundation: Understand the definition and types of Anemia\n",
      "\n",
      "‚úÖ Success Criteria:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  1. Define Anemia\n",
      "  2. List the main types of Anemia\n",
      "  3. Explain the difference between iron-deficiency Anemia and\n",
      "     vitamin-deficiency Anemia\n",
      "\n",
      "üîç Verification Method:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Explain Anemia to a peer and provide examples of each type\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                                üìç CHECKPOINT #2                                 \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìù Description:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Application: Identify the clinical presentation and risk factors of\n",
      "  Anemia\n",
      "\n",
      "‚úÖ Success Criteria:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  1. Describe the common symptoms of Anemia\n",
      "  2. List the risk factors for developing Anemia\n",
      "  3. Explain how to perform a physical examination to suspect Anemia\n",
      "\n",
      "üîç Verification Method:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Present a case study of a patient with Anemia and discuss the\n",
      "  clinical presentation and risk factors\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                                üìç CHECKPOINT #3                                 \n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìù Description:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Mastery: Develop a diagnostic approach to Anemia\n",
      "\n",
      "‚úÖ Success Criteria:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  1. Explain the laboratory tests used to diagnose Anemia\n",
      "  2. Describe the interpretation of laboratory results\n",
      "  3. Develop a diagnostic algorithm for Anemia\n",
      "\n",
      "üîç Verification Method:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Create a diagnostic flowchart for Anemia and defend the approach with\n",
      "  evidence-based medicine\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"20\"}}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print_checkpoints(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/sseadmin/Documents/personal_repos/Gen-ai-learn/.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def create_checkpoint_editor(checkpoints_model: Checkpoints):\n",
    "    \"\"\"\n",
    "    Creates an interactive checkpoint editor using a Pydantic model.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints_model: Pydantic model of Checkpoints class\n",
    "    \"\"\"\n",
    "    # Convert to list of dictionaries for easier editing\n",
    "    checkpoints = [cp.model_dump() for cp in checkpoints_model.checkpoints]\n",
    "    checkpoints_widgets = []\n",
    "    accepted_checkpoints = []\n",
    "    \n",
    "    def create_criterion_widget(checkpoint_index: int, criterion_value: str = \"\", criterion_index: int = None):\n",
    "        \"\"\"Creates a widget for a single criterion with a delete button\"\"\"\n",
    "        criterion_container = widgets.HBox([\n",
    "            widgets.Text(\n",
    "                value=criterion_value,\n",
    "                description=f'{criterion_index + 1}.' if criterion_index is not None else 'New',\n",
    "                layout=widgets.Layout(width='85%')\n",
    "            ),\n",
    "            widgets.Button(\n",
    "                description='Delete',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(width='15%')\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        def on_criterion_change(change):\n",
    "            nonlocal criterion_index\n",
    "            if criterion_index is not None:\n",
    "                checkpoints[checkpoint_index]['criteria'][criterion_index] = change['new']\n",
    "        \n",
    "        def remove_criterion(b):\n",
    "            if criterion_index is not None:\n",
    "                checkpoints[checkpoint_index]['criteria'].pop(criterion_index)\n",
    "                update_checkpoint_widget(checkpoint_index)\n",
    "        \n",
    "        criterion_container.children[0].observe(on_criterion_change, names='value')\n",
    "        criterion_container.children[1].on_click(remove_criterion)\n",
    "        \n",
    "        return criterion_container\n",
    "    \n",
    "    def create_checkpoint_widget(checkpoint: dict, index: int):\n",
    "        \"\"\"Creates a widget for a single checkpoint\"\"\"\n",
    "        \n",
    "        def on_accept_change(change):\n",
    "            if change['new']:\n",
    "                accepted_checkpoints.append(index)\n",
    "            else:\n",
    "                if index in accepted_checkpoints:\n",
    "                    accepted_checkpoints.remove(index)\n",
    "        \n",
    "        def on_description_change(change):\n",
    "            checkpoints[index]['description'] = change['new']\n",
    "        \n",
    "        def on_verification_change(change):\n",
    "            checkpoints[index]['verification'] = change['new']\n",
    "        \n",
    "        def add_criterion(b):\n",
    "            checkpoints[index]['criteria'].append(\"\")\n",
    "            update_checkpoint_widget(index)\n",
    "        \n",
    "        def remove_checkpoint(b):\n",
    "            checkpoints.pop(index)\n",
    "            update_all_checkpoints()\n",
    "        \n",
    "        # Header with checkbox and delete button\n",
    "        header = widgets.HBox([\n",
    "            widgets.HTML(f'<h3 style=\"margin: 0;\">Checkpoint {index + 1}</h3>'),\n",
    "            widgets.Checkbox(\n",
    "                value=False,\n",
    "                description='Accept',\n",
    "                indent=False,\n",
    "                layout=widgets.Layout(margin='5px 0 0 20px')\n",
    "            ),\n",
    "            widgets.Button(\n",
    "                description='Delete checkpoint',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(margin='0 0 0 20px')\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Description\n",
    "        description = widgets.Textarea(\n",
    "            value=checkpoint['description'],\n",
    "            description='Description:',\n",
    "            layout=widgets.Layout(width='95%', height='60px')\n",
    "        )\n",
    "        \n",
    "        # Criteria\n",
    "        criteria_label = widgets.HTML('<b>Criteria:</b>')\n",
    "        criteria_container = widgets.VBox([\n",
    "            create_criterion_widget(index, criterion, i)\n",
    "            for i, criterion in enumerate(checkpoint['criteria'])\n",
    "        ])\n",
    "        \n",
    "        # Add criterion button\n",
    "        add_criterion_btn = widgets.Button(\n",
    "            description='Add criterion',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        # Verification\n",
    "        verification = widgets.Textarea(\n",
    "            value=checkpoint['verification'],\n",
    "            description='Verification:',\n",
    "            layout=widgets.Layout(width='95%', height='60px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        separator = widgets.HTML('<hr style=\"margin: 20px 0;\">')\n",
    "        \n",
    "        # Combine all elements\n",
    "        checkpoint_widget = widgets.VBox([\n",
    "            header,\n",
    "            description,\n",
    "            criteria_label,\n",
    "            criteria_container,\n",
    "            add_criterion_btn,\n",
    "            verification,\n",
    "            separator\n",
    "        ])\n",
    "        \n",
    "        # Add observers and handlers\n",
    "        header.children[1].observe(on_accept_change, names='value')\n",
    "        header.children[2].on_click(remove_checkpoint)\n",
    "        description.observe(on_description_change, names='value')\n",
    "        verification.observe(on_verification_change, names='value')\n",
    "        add_criterion_btn.on_click(add_criterion)\n",
    "        \n",
    "        return checkpoint_widget\n",
    "    \n",
    "    def update_checkpoint_widget(index: int):\n",
    "        \"\"\"Updates a single checkpoint widget\"\"\"\n",
    "        if 0 <= index < len(checkpoints):\n",
    "            checkpoints_widgets[index] = create_checkpoint_widget(checkpoints[index], index)\n",
    "            update_main_container()\n",
    "    \n",
    "    def update_all_checkpoints():\n",
    "        \"\"\"Updates all checkpoint widgets\"\"\"\n",
    "        nonlocal checkpoints_widgets\n",
    "        checkpoints_widgets = [\n",
    "            create_checkpoint_widget(checkpoint, i)\n",
    "            for i, checkpoint in enumerate(checkpoints)\n",
    "        ]\n",
    "        update_main_container()\n",
    "    \n",
    "    def add_new_checkpoint(b):\n",
    "        \"\"\"Adds a new checkpoint\"\"\"\n",
    "        checkpoints.append({\n",
    "            'description': '',\n",
    "            'criteria': [],\n",
    "            'verification': ''\n",
    "        })\n",
    "        update_all_checkpoints()\n",
    "    \n",
    "    def get_pydantic_model() -> Checkpoints:\n",
    "        \"\"\"Converts the current editor state back to a Pydantic model\"\"\"\n",
    "        return Checkpoints(checkpoints=[\n",
    "            LearningCheckpoint(**checkpoint)\n",
    "            for checkpoint in checkpoints\n",
    "        ])\n",
    "    \n",
    "    # Create initial checkpoint widgets\n",
    "    checkpoints_widgets = [\n",
    "        create_checkpoint_widget(checkpoint, i)\n",
    "        for i, checkpoint in enumerate(checkpoints)\n",
    "    ]\n",
    "    \n",
    "    # Add new checkpoint button\n",
    "    add_checkpoint_btn = widgets.Button(\n",
    "        description='Add checkpoint',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(margin='20px 0')\n",
    "    )\n",
    "    add_checkpoint_btn.on_click(add_new_checkpoint)\n",
    "    \n",
    "    # Main container\n",
    "    main_container = widgets.VBox(\n",
    "        checkpoints_widgets + [add_checkpoint_btn],\n",
    "        layout=widgets.Layout(\n",
    "            padding='20px',\n",
    "            border='1px solid #ddd',\n",
    "            border_radius='5px'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def update_main_container():\n",
    "        \"\"\"Updates the main container\"\"\"\n",
    "        main_container.children = tuple(checkpoints_widgets + [add_checkpoint_btn])\n",
    "    \n",
    "    # Add method to container to retrieve data later\n",
    "    main_container.get_model = get_pydantic_model\n",
    "    \n",
    "    return main_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = event['checkpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb19f9f296f472bb3994d3f632eac32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<h3 style=\"margin: 0;\">Checkpoint 1</h3>'), Checkbox(‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "editor = create_checkpoint_editor(checkpoints)\n",
    "display(editor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
